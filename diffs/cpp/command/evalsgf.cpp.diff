--- cpp/command/evalsgf.cpp [lightvector:master]+++ cpp/command/evalsgf.cpp [hzyhhzy:Reversi2022]@@ -14,7 +14,6 @@ 
 int MainCmds::evalsgf(const vector<string>& args) {
   Board::initHash();
-  ScoreValue::initTables();
   Rand seedRand;
 
   ConfigParser cfg;
@@ -33,11 +32,7 @@   bool printPolicy;
   bool printLogPolicy;
   bool printDirichletShape;
-  bool printScoreNow;
-  bool printRootEndingBonus;
-  bool printLead;
   bool printAvgShorttermError;
-  bool printSharpScore;
   bool printGraph;
   int printMaxDepth;
   bool rawNN;
@@ -63,11 +58,7 @@     TCLAP::SwitchArg printPolicyArg("","print-policy","Print policy");
     TCLAP::SwitchArg printLogPolicyArg("","print-log-policy","Print log policy");
     TCLAP::SwitchArg printDirichletShapeArg("","print-dirichlet-shape","Print dirichlet shape");
-    TCLAP::SwitchArg printScoreNowArg("","print-score-now","Print score now");
-    TCLAP::SwitchArg printRootEndingBonusArg("","print-root-ending-bonus","Print root ending bonus now");
-    TCLAP::SwitchArg printLeadArg("","print-lead","Compute and print lead");
     TCLAP::SwitchArg printAvgShorttermErrorArg("","print-avg-shortterm-error","Compute and print avgShorttermError");
-    TCLAP::SwitchArg printSharpScoreArg("","print-sharp-score","Compute and print sharp weighted score");
     TCLAP::SwitchArg printGraphArg("","print-graph","Print graph structure of the search");
     TCLAP::ValueArg<int> printMaxDepthArg("","print-max-depth","How deep to print",false,1,"DEPTH");
     TCLAP::SwitchArg rawNNArg("","raw-nn","Perform single raw neural net eval");
@@ -92,11 +83,7 @@     cmd.add(printPolicyArg);
     cmd.add(printLogPolicyArg);
     cmd.add(printDirichletShapeArg);
-    cmd.add(printScoreNowArg);
-    cmd.add(printRootEndingBonusArg);
-    cmd.add(printLeadArg);
     cmd.add(printAvgShorttermErrorArg);
-    cmd.add(printSharpScoreArg);
     cmd.add(printGraphArg);
     cmd.add(printMaxDepthArg);
     cmd.add(rawNNArg);
@@ -119,11 +106,7 @@     printPolicy = printPolicyArg.getValue();
     printLogPolicy = printLogPolicyArg.getValue();
     printDirichletShape = printDirichletShapeArg.getValue();
-    printScoreNow = printScoreNowArg.getValue();
-    printRootEndingBonus = printRootEndingBonusArg.getValue();
-    printLead = printLeadArg.getValue();
     printAvgShorttermError = printAvgShorttermErrorArg.getValue();
-    printSharpScore = printSharpScoreArg.getValue();
     printGraph = printGraphArg.getValue();
     printMaxDepth = printMaxDepthArg.getValue();
     rawNN = rawNNArg.getValue();
@@ -176,7 +159,7 @@     if(moveNum > moves.size())
       throw StringError("Move num " + Global::intToString(moveNum) + " requested but sgf has only " + Global::int64ToString(moves.size()));
 
-    sgf->playMovesTolerant(board,nextPla,hist,moveNum,false);
+    sgf->playMovesTolerant(board,nextPla,hist,moveNum);
 
     vector<Loc> extraMoveLocs = Location::parseSequence(extraMoves,board);
     for(size_t i = 0; i<extraMoveLocs.size(); i++) {
@@ -186,7 +169,7 @@         cerr << "Extra illegal move for " << PlayerIO::colorToChar(nextPla) << ": " << Location::toString(loc,board) << endl;
         throw StringError("Illegal extra move");
       }
-      hist.makeBoardMoveAssumeLegal(board,loc,nextPla,NULL);
+      hist.makeBoardMoveAssumeLegal(board,loc,nextPla);
       nextPla = getOpp(nextPla);
     }
   };
@@ -207,8 +190,8 @@ 
   //Load neural net and start bot------------------------------------------
 
-  const bool logToStdoutDefault = true;
-  Logger logger(&cfg, logToStdoutDefault);
+  Logger logger;
+  logger.setLogToStdout(true);
   logger.write("Engine starting...");
 
   SearchParams params = Setup::loadSingleParams(cfg,Setup::SETUP_FOR_GTP);
@@ -260,38 +243,6 @@     }
   }
 
-  // {
-  //   sgf->setupInitialBoardAndHist(initialRules, board, nextPla, hist);
-  //   vector<Move>& moves = sgf->moves;
-
-  //   for(size_t i = 0; i<moves.size(); i++) {
-  //     bool preventEncore = false;
-  //     bool suc = hist.makeBoardMoveTolerant(board,moves[i].loc,moves[i].pla,preventEncore);
-  //     assert(suc);
-  //     nextPla = getOpp(moves[i].pla);
-
-  //     MiscNNInputParams nnInputParams;
-  //     nnInputParams.nnPolicyTemperature = 1.2f;
-  //     NNResultBuf buf;
-  //     bool skipCache = true;
-  //     bool includeOwnerMap = false;
-  //     nnEval->evaluate(board,hist,nextPla,nnInputParams,buf,skipCache,includeOwnerMap);
-
-  //     NNOutput* nnOutput = buf.result.get();
-  //     vector<double> probs;
-  //     for(int y = 0; y<board.y_size; y++) {
-  //       for(int x = 0; x<board.x_size; x++) {
-  //         int pos = NNPos::xyToPos(x,y,nnOutput->nnXLen);
-  //         float prob = nnOutput->policyProbs[pos];
-  //         probs.push_back(prob);
-  //       }
-  //     }
-  //     std::sort(probs.begin(),probs.end());
-  //     cout << probs[probs.size()-1] << " " << probs[probs.size()-2] << " " << probs[probs.size()-3] << endl;
-  //   }
-  //   return 0;
-  // }
-
   //Check for unused config keys
   cfg.warnUnusedKeys(cerr,&logger);
 
@@ -304,7 +255,6 @@     nnEval->evaluate(board,hist,nextPla,nnInputParams,buf,skipCache,includeOwnerMap);
 
     cout << "Rules: " << hist.rules << endl;
-    cout << "Encore phase " << hist.encorePhase << endl;
     Board::printBoard(cout, board, Board::NULL_LOC, &(hist.moveHistory));
     buf.result->debugPrint(cout,board);
     return 0;
@@ -329,7 +279,6 @@   const Search* search = bot->getSearchStopAndWait();
   ostringstream sout;
   sout << "Rules: " << hist.rules << endl;
-  sout << "Encore phase " << hist.encorePhase << endl;
   Board::printBoard(sout, board, Board::NULL_LOC, &(hist.moveHistory));
 
   if(options.branch_.size() > 0) {
@@ -343,7 +292,7 @@         cerr << "Branch Illegal move for " << PlayerIO::colorToChar(pla) << ": " << Location::toString(loc,board) << endl;
         return 1;
       }
-      copyHist.makeBoardMoveAssumeLegal(copy,loc,pla,NULL);
+      copyHist.makeBoardMoveAssumeLegal(copy,loc,pla);
       pla = getOpp(pla);
     }
     Board::printBoard(sout, copy, Board::NULL_LOC, &(copyHist.moveHistory));
@@ -378,13 +327,6 @@     }
   }
 
-  if(printSharpScore) {
-    double ret = 0.0;
-    bool suc = search->getSharpScore(NULL,ret);
-    assert(suc);
-    (void)suc;
-    cout << "White sharp score " << ret << endl;
-  }
 
   if(printPolicy) {
     const NNOutput* nnOutput = search->rootNode->getNNOutput();
@@ -451,31 +393,6 @@     }
   }
 
-  if(printScoreNow) {
-    sout << "Score now (ROOT position):\n";
-    Board copy(board);
-    BoardHistory copyHist(hist);
-    Color area[Board::MAX_ARR_SIZE];
-    copyHist.endAndScoreGameNow(copy,area);
-
-    for(int y = 0; y<copy.y_size; y++) {
-      for(int x = 0; x<copy.x_size; x++) {
-        Loc l = Location::getLoc(x,y,copy.x_size);
-        sout << PlayerIO::colorToChar(area[l]);
-      }
-      sout << endl;
-    }
-    sout << endl;
-
-    sout << "Komi: " << copyHist.rules.komi << endl;
-    sout << "WBonus: " << copyHist.whiteBonusScore << endl;
-    sout << "Final: "; WriteSgf::printGameResult(sout, copyHist); sout << endl;
-  }
-
-  if(printRootEndingBonus) {
-    sout << "Ending bonus (ROOT position)\n";
-    search->printRootEndingScoreValueBonus(sout);
-  }
 
   sout << "Time taken: " << timer.getSeconds() << "\n";
   sout << "Root visits: " << search->getRootVisits() << "\n";
@@ -491,14 +408,6 @@   search->printTree(sout, search->rootNode, options, perspective);
   logger.write(sout.str());
 
-  if(printLead) {
-    BoardHistory hist2(hist);
-    double lead = PlayUtils::computeLead(
-      bot->getSearchStopAndWait(), NULL, board, hist2, nextPla,
-      20, OtherGameProperties()
-    );
-    cout << "LEAD: " << lead << endl;
-  }
 
   if(printGraph) {
     std::reverse(nodes.begin(),nodes.end());
@@ -524,7 +433,6 @@   delete nnEval;
   NeuralNet::globalCleanup();
   delete sgf;
-  ScoreValue::freeTables();
 
   return 0;
 }
